{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read in the MVPA data\n",
    "bring it into the right shape to feed it into the CNN\n",
    "\n",
    "first do it with one MVPA component\n",
    "then do it with all MVPA components by concatenating them into a dense layer\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'module_util' from 'tensorflow.python.tools' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split, cross_val_score\n\u001b[1;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers\n",
      "File \u001b[1;32mc:\\Users\\tahendry\\switchdrive\\Studium_Master\\03_HS22\\AA_Master_Thesis\\02_Python_Scripts\\env_01\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'module_util' from 'tensorflow.python.tools' (unknown location)"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BETA_Subject001_Condition002_Measure002_Component001.nii', 'BETA_Subject002_Condition002_Measure002_Component001.nii', 'BETA_Subject003_Condition002_Measure002_Component001.nii', 'BETA_Subject004_Condition002_Measure002_Component001.nii', 'BETA_Subject005_Condition002_Measure002_Component001.nii']\n"
     ]
    }
   ],
   "source": [
    "### prepare the MVPA data\n",
    "file_path = \"X:/MasterThesis_Reto/Denoised_Data_6mm\"\n",
    "path_content = os.listdir(os.path.join(file_path, \"MVPA_data\"))\n",
    "\n",
    "# make two lists with pre (Condition002) and post (Condition003) data of first component\n",
    "comp1_pre = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition002\" in x])\n",
    "comp1_post = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition003\" in x])\n",
    "\n",
    "print(comp1_pre[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset with the difference of pre and post data\n",
    "comp1_diff = []\n",
    "for pre, post in zip(comp1_pre, comp1_post):\n",
    "    pre_vol = nib.load(os.path.join(file_path, \"MVPA_data\", pre))\n",
    "    post_vol = nib.load(os.path.join(file_path, \"MVPA_data\", post))\n",
    "    pre_vol_data = pre_vol.get_fdata()\n",
    "    post_vol_data = post_vol.get_fdata()\n",
    "    diff_vol_data = post_vol_data - pre_vol_data\n",
    "    comp1_diff.append(diff_vol_data)\n",
    "\n",
    "# check the shape of the data\n",
    "print(comp1_diff[0].shape)\n",
    "\n",
    "# check the type of the data\n",
    "print(type(comp1_diff[0]))\n",
    "\n",
    "# takes about 3m to run on Dell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 91, 109, 91)\n"
     ]
    }
   ],
   "source": [
    "# stack the data to later use it as input for the CNN\n",
    "# note: the first dimension is the number of samples\n",
    "inpt_comp1_diff = np.stack(comp1_diff, axis=0)\n",
    "print(inpt_comp1_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conn_SubjNr</th>\n",
       "      <th>VPNr</th>\n",
       "      <th>Cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Conn_SubjNr  VPNr  Cond\n",
       "63           64    80     0\n",
       "64           65    83     0\n",
       "65           66    86     1\n",
       "66           67    87     1\n",
       "67           68    88     0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the excel-file with the labels\n",
    "label_path = \"X:/MasterThesis_Reto\"\n",
    "label_file = \"Conn_IDs_Matching.xlsx\"\n",
    "# read excel with only the first three columns\n",
    "label_df = (pd.read_excel(os.path.join(label_path, label_file),\n",
    "                            usecols=[0, 1, 2])\n",
    "            .replace({\"Cond\": {1: 0}})\n",
    "            .replace({\"Cond\": {2: 1}})\n",
    "            )\n",
    "\n",
    "label_df[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built a keras CNN model with functional API\n",
    "inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "x = layers.Conv3D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling3D(3)(x)\n",
    "x = layers.Conv3D(64, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling3D(3)(x)\n",
    "x = layers.Conv3D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# define the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test data\n",
    "# use 80% of the data for training and 20% for testing\n",
    "# use cross-validation to get a better estimate of the model performance\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inpt_comp1_diff, label_df[\"Cond\"], test_size=0.2, random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(model, inpt_comp1_diff, label_df[\"Cond\"], cv=5)\n",
    "print(cv_scores)\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(inpt_comp1_diff, label_df[\"Cond\"], batch_size=1, epochs=10)\n",
    "\n",
    "# evaluate the model\n",
    "model.evaluate(inpt_comp1_diff, label_df[\"Cond\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"binary_accuracy\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"loss\", \"accuracy\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# save the model\n",
    "model.save(\"X:/MasterThesis_Reto/3d_cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946f6e6a8d11e7593d015c40743c23d87faf58a1213a90dca87ce1f046c0a55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
