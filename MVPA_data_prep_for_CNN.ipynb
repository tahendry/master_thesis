{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: bath normalization and residual connection are especially important for deep networks\n",
    "\n",
    "# TODO: do I only need to normalize the test data? \n",
    "#       Or only take the mean and std of the training data and apply it to all data?\n",
    "\n",
    "# TODO: maybe data augmentation helps to improve the model performance\n",
    "\n",
    "# TODO: one hot encode the labels, convert input data into a tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, callbacks, initializers\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='dalcowks', release='5.13.0-40-generic', version='#45~20.04.1-Ubuntu SMP Mon Apr 4 09:38:31 UTC 2022', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# path to data\n",
    "#  - on Windows: C:/Users/tahendry/Desktop/Masterthesis_Reto/\n",
    "#  - on Linux:   ../data/\n",
    "\n",
    "try:\n",
    "    print(os.uname())\n",
    "    data_path = \"../data/\"\n",
    "except:\n",
    "    print(\"Windows\")\n",
    "    data_path = \"C:/Users/tahendry/Desktop/Masterthesis_Reto/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conn_SubjNr</th>\n",
       "      <th>VPNr</th>\n",
       "      <th>Cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conn_SubjNr  VPNr  Cond\n",
       "0            1     1     0\n",
       "1            2     2     0\n",
       "2            3     4     0\n",
       "3            4     6     1\n",
       "4            5     7     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the excel-file with the labels\n",
    "label_file = \"Conn_IDs_Matching.xlsx\"\n",
    "\n",
    "# read excel with only the first three columns\n",
    "label_df = (pd.read_excel(os.path.join(data_path, label_file),\n",
    "                            usecols=[0, 1, 2])\n",
    "            .replace({\"Cond\": {1: 0}})\n",
    "            .replace({\"Cond\": {2: 1}})\n",
    "            )\n",
    "\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BETA_Subject001_Condition002_Measure002_Component001.nii', 'BETA_Subject002_Condition002_Measure002_Component001.nii', 'BETA_Subject003_Condition002_Measure002_Component001.nii', 'BETA_Subject004_Condition002_Measure002_Component001.nii', 'BETA_Subject005_Condition002_Measure002_Component001.nii']\n"
     ]
    }
   ],
   "source": [
    "# read MVPA data\n",
    "path_content = os.listdir(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\"))\n",
    "\n",
    "# make two lists with pre (Condition002) and post (Condition003) data of first component\n",
    "comp1_pre = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition002\" in x])\n",
    "comp1_post = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition003\" in x])\n",
    "\n",
    "print(comp1_pre[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset with the difference of pre and post data\n",
    "comp1_diff = []\n",
    "for pre, post in zip(comp1_pre, comp1_post):\n",
    "    pre_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", pre))\n",
    "    post_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", post))\n",
    "    pre_vol_data = pre_vol.get_fdata()\n",
    "    post_vol_data = post_vol.get_fdata()\n",
    "    diff_vol_data = post_vol_data - pre_vol_data\n",
    "    comp1_diff.append(diff_vol_data)\n",
    "\n",
    "# check the shape of the data\n",
    "print(comp1_diff[0].shape)\n",
    "\n",
    "# check the type of the data\n",
    "print(type(comp1_diff[0]))\n",
    "\n",
    "# takes about 4 mins to run on Dell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of one list element before stacking: comp1_diff[0].shape=(91, 109, 91)\n",
      "inpt_comp1_diff.shape=(68, 91, 109, 91, 1)\n",
      "inpt_comp1_diff.mean()=1.2019033790773762e-16\n",
      "inpt_comp1_diff.std()=0.9999999999999889\n"
     ]
    }
   ],
   "source": [
    "# stack the data to later use it as input for the CNN\n",
    "# note: the first dimension is the number of samples\n",
    "print(f\"shape of one list element before stacking: {comp1_diff[0].shape=}\")\n",
    "inpt_comp1_diff = np.stack(comp1_diff, axis=0)\n",
    "\n",
    "# expand the dimensions to fit the input shape of the CNN\n",
    "# note: the last dimension is the number of channels\n",
    "inpt_comp1_diff = np.expand_dims(inpt_comp1_diff, axis=-1)\n",
    "\n",
    "# normalize the input data (zero mean, unit variance)\n",
    "# note: a CNN works best with normalized data\n",
    "inpt_comp1_diff = (inpt_comp1_diff - inpt_comp1_diff.mean()) / inpt_comp1_diff.std()\n",
    "\n",
    "print(f\"{inpt_comp1_diff.shape=}\",\n",
    "      f\"{inpt_comp1_diff.mean()=}\",\n",
    "      f\"{inpt_comp1_diff.std()=}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape=(54, 91, 109, 91, 1)\n",
      "x_test.shape=(14, 91, 109, 91, 1)\n",
      "y_train.shape=(54,)\n",
      "y_test.shape=(14,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test data\n",
    "# use 80% of the data for training and 20% for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(inpt_comp1_diff, \n",
    "                                                    label_df[\"Cond\"], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# check the shape of the data\n",
    "print(f\"{x_train.shape=}\",\n",
    "        f\"{x_test.shape=}\",\n",
    "        f\"{y_train.shape=}\",\n",
    "        f\"{y_test.shape=}\", sep=\"\\n\")\n",
    "\n",
    "# prepare for k-fold cross-validation\n",
    "# note: StratifiedKFold ensures that the proportion of samples of each class is the same in each fold\n",
    "nbr_of_folds = 12\n",
    "kfold = StratifiedKFold(n_splits=nbr_of_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built some models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 91, 109, 91, 1)]  0         \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 89, 107, 89, 16)   448       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 89, 107, 89, 16)   0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 44, 53, 44, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 44, 53, 44, 16)   64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 42, 51, 42, 32)    13856     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 42, 51, 42, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 21, 25, 21, 32)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 21, 25, 21, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 352800)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               45158528  \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,173,665\n",
      "Trainable params: 45,173,313\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa749c3b100>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identical 3D-CNN model to the M2DCNN Paper\n",
    "\n",
    "# built a keras CNN model with functional API\n",
    "def build_compile_3DCNN(summary=False):\n",
    "\n",
    "    # layer 1\n",
    "    inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "    x = layers.Conv3D(filters=16, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (inputs)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "\n",
    "    # layer 2\n",
    "    x = layers.Conv3D(filters=32, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization()  (x)\n",
    "\n",
    "    # flatten and create dense layer\n",
    "    x = layers.Flatten() (x)\n",
    "    x = layers.Dense(units=128,\n",
    "                     kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "    x = keras.layers.Dropout(0.5) (x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "\n",
    "    # define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if summary == True:\n",
    "        model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    my_adam = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    model.compile(optimizer=my_adam,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=[keras.metrics.Accuracy(name=\"Accuracy\")])\n",
    "\n",
    "    return model\n",
    "\n",
    "build_compile_3DCNN(summary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s2D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 91, 109, 91, 1)]  0         \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 89, 107, 89, 16)   448       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 89, 107, 89, 16)   0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 44, 53, 44, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 44, 53, 44, 16)   64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 42, 51, 42, 32)    13856     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 42, 51, 42, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 21, 25, 21, 32)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 21, 25, 21, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 352800)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               45158528  \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,173,665\n",
      "Trainable params: 45,173,313\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa749c3b100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identical 3D-SepConv model to the M2DCNN Paper\n",
    "\n",
    "# built a keras CNN model with functional API\n",
    "def build_compile_3DCNN(summary=False):\n",
    "\n",
    "    # layer 1\n",
    "    inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "    x = layers.Conv3D(filters=16, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (inputs)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "\n",
    "    # layer 2\n",
    "    x = layers.Conv3D(filters=32, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization()  (x)\n",
    "\n",
    "    # flatten and create dense layer\n",
    "    x = layers.Flatten() (x)\n",
    "    x = layers.Dense(units=128,\n",
    "                     kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "    x = keras.layers.Dropout(0.5) (x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "\n",
    "    # define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if summary == True:\n",
    "        model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    my_adam = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    model.compile(optimizer=my_adam,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=[keras.metrics.Accuracy(name=\"Accuracy\")])\n",
    "\n",
    "    return model\n",
    "\n",
    "build_compile_3DCNN(summary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M2D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 91, 109, 91, 1)]  0         \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 89, 107, 89, 16)   448       \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 89, 107, 89, 16)   0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 44, 53, 44, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 44, 53, 44, 16)   64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 42, 51, 42, 32)    13856     \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 42, 51, 42, 32)    0         \n",
      "                                                                 \n",
      " max_pooling3d_9 (MaxPooling  (None, 21, 25, 21, 32)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 21, 25, 21, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 352800)            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               45158528  \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,173,665\n",
      "Trainable params: 45,173,313\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa749c3b100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# identical 3D-SepConv model to the M2DCNN Paper\n",
    "\n",
    "# built a keras CNN model with functional API\n",
    "def build_compile_3DCNN(summary=False):\n",
    "\n",
    "    # layer 1\n",
    "    inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "    x = layers.Conv3D(filters=16, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (inputs)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "\n",
    "    # layer 2\n",
    "    x = layers.Conv3D(filters=32, \n",
    "                      kernel_size=3, \n",
    "                      strides=1,\n",
    "                      kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = layers.MaxPooling3D(pool_size=2, \n",
    "                            strides=2, \n",
    "                            padding='valid') (x)\n",
    "    x = keras.layers.BatchNormalization()  (x)\n",
    "\n",
    "    # flatten and create dense layer\n",
    "    x = layers.Flatten() (x)\n",
    "    x = layers.Dense(units=128,\n",
    "                     kernel_initializer=initializers.glorot_normal()) (x)\n",
    "    x = keras.layers.LeakyReLU() (x)\n",
    "    x = keras.layers.BatchNormalization() (x)\n",
    "    x = keras.layers.Dropout(0.5) (x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "\n",
    "    # define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    if summary == True:\n",
    "        model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    my_adam = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    model.compile(optimizer=my_adam,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=[keras.metrics.Accuracy(name=\"Accuracy\")])\n",
    "\n",
    "    return model\n",
    "\n",
    "build_compile_3DCNN(summary=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback to stop training when loss does not improve anymore and save the best model\n",
    "callback_list = [callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "                 callbacks.ModelCheckpoint(filepath=\"./MVPA_CNN_model_cv.keras\", \n",
    "                                            monitor=\"val_loss\",\n",
    "                                            save_best_only=True)]\n",
    "\n",
    "# create empty lists to store the results of the k-fold cross-validation\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "history_list = []\n",
    "\n",
    "# k-fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(x_train, y_train)):\n",
    "    if fold == 0:\n",
    "        print(f\"cross validation started...\", \n",
    "                f\"size of the training data: {len(train_idx)}\",\n",
    "                f\"size of the test data: {len(test_idx)}\", \n",
    "                sep=\"\\n\")\n",
    "\n",
    "    # create the folds\n",
    "    print(f\"Fold {fold+1} of {nbr_of_folds}\")\n",
    "    x_train_fold = x_train[train_idx]\n",
    "    x_test_fold = x_train[test_idx]\n",
    "    y_train_fold = y_train.iloc[train_idx]\n",
    "    y_test_fold = y_train.iloc[test_idx]\n",
    "\n",
    "    # print shape of the folds\n",
    "    # print(f\"{x_train_fold.shape=}\",\n",
    "    #     f\"{x_test_fold.shape=}\",\n",
    "    #     f\"{y_train_fold.shape=}\",\n",
    "    #     f\"{y_test_fold.shape=}\", sep=\"\\n\")\n",
    "\n",
    "    # build and compile the model\n",
    "    model = build_and_compile_model()\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(x_train_fold, y_train_fold,\n",
    "                        epochs=20,\n",
    "                        batch_size=4,\n",
    "                        validation_data=(x_test_fold, y_test_fold),\n",
    "                        callbacks=callback_list,\n",
    "                        verbose=1)\n",
    "    history_list.append(history)\n",
    "\n",
    "    # evaluate the model\n",
    "    fold_loss = model.evaluate(x_test_fold, y_test_fold, verbose=0)[0]\n",
    "    fold_acc = model.evaluate(x_test_fold, y_test_fold, verbose=0)[1]\n",
    "    val_loss.append(fold_loss)\n",
    "    val_acc.append(fold_acc)\n",
    "    print(f\"Loss: {fold_loss}\", f\"Accuracy: {fold_acc}\", sep=\"\\n\")\n",
    "\n",
    "# print the mean of the validation loss and accuracy\n",
    "print(f\"Mean validation loss: {np.mean(val_loss)}\",\n",
    "        f\"Mean validation accuracy: {np.mean(val_acc)}\", sep=\"\\n\")\n",
    "        \n",
    "# save the model\n",
    "# model.save(\"X:/MasterThesis_Reto/3d_cnn_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplot to show all folds from cross-validation\n",
    "fig, axs = plt.subplots(3, 4, figsize=(12, 6))\n",
    "axs = axs.ravel()\n",
    "for i, history in enumerate(history_list):\n",
    "    axs[i].plot(history.history[\"loss\"][1:])\n",
    "    axs[i].plot(history.history[\"val_loss\"][1:])\n",
    "    axs[i].plot(history.history[\"Accuracy\"][1:])\n",
    "    axs[i].plot(history.history[\"val_Accuracy\"][1:])\n",
    "    axs[i].set_title(f\"Fold {i+1}\")\n",
    "    axs[i].set_ylabel(\"loss\")\n",
    "    axs[i].set_xlabel(\"epoch\")\n",
    "    axs[i].grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend([\"loss\", \"val_loss\", \"accuracy\", \"val_Accuracy\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model with the entire test data (no val. data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 2.4220 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 7s 368ms/step - loss: 2.4220 - Accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.7245 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 360ms/step - loss: 0.7245 - Accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4843 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 364ms/step - loss: 0.4843 - Accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4985 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 362ms/step - loss: 0.4985 - Accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4458 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 346ms/step - loss: 0.4458 - Accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3537 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 355ms/step - loss: 0.3537 - Accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1558 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 344ms/step - loss: 0.1558 - Accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3766 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 350ms/step - loss: 0.3766 - Accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1752 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 352ms/step - loss: 0.1752 - Accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3764 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 354ms/step - loss: 0.3764 - Accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1787 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 350ms/step - loss: 0.1787 - Accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1657 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 344ms/step - loss: 0.1657 - Accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1239 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 348ms/step - loss: 0.1239 - Accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1118 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 341ms/step - loss: 0.1118 - Accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2441 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 344ms/step - loss: 0.2441 - Accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2563 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 355ms/step - loss: 0.2563 - Accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6023 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 379ms/step - loss: 0.6023 - Accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3825 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 373ms/step - loss: 0.3825 - Accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1028 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 331ms/step - loss: 0.1028 - Accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1932 - Accuracy: 0.0000e+00WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_Accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 5s 339ms/step - loss: 0.1932 - Accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# train with entire training data (no validation data)\n",
    "# callback to stop training when loss does not improve anymore and save the best model\n",
    "early_stop = callbacks.EarlyStopping(monitor=\"loss\", patience=6, mode=\"auto\")\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=\"./MVPA_CNN_model.keras\", \n",
    "                                        monitor=\"val_Accuracy\",\n",
    "                                        save_best_only=True,\n",
    "                                        mode=\"auto\",\n",
    "                                        verbose=1)\n",
    "callback_list = [early_stop, checkpoint]\n",
    "\n",
    "# build and compile the model\n",
    "model = build_compile_3DCNN()\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=4,\n",
    "                    callbacks=callback_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 415ms/step - loss: 1.9603 - Accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the best model\n",
    "model = keras.models.load_model(\"./MVPA_CNN_model.keras\")\n",
    "\n",
    "# evaluate the model\n",
    "model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# plot the training history\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "# plt.plot(history.history[\"val_loss\"])\n",
    "plt.plot(history.history[\"Accuracy\"])\n",
    "# plt.plot(history.history[\"val_Accuracy\"])\n",
    "plt.title(\"training history\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"loss\", \"val_loss\", \"accuracy\", \"val_Accuracy\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build and compile the model for hyperparameter tuning\n",
    "\n",
    "def build_and_compile_model_test(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search. Model is compiled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : model\n",
    "        Compiled keras model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "    \n",
    "    # Tune the number of hidden CNN layers (pair of Conv3D and MaxPool) and filters + kernel_size in each hidden layer.\n",
    "    # Number of hidden layers: 1 - 5\n",
    "    # Number of filters: 16 - 512 with stepsize of 32\n",
    "    # Kernel size: 3 - 5 with stepsize of 2\n",
    "        \n",
    "    x = keras.layers.Conv3D(\n",
    "        filters=hp.Int(\"filters\", min_value=16, max_value=512, step=32),\n",
    "        kernel_size=3,\n",
    "        activation=\"relu\", \n",
    "        padding=\"same\")(inputs)\n",
    "\n",
    "    x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    \n",
    "    # Flatten the output of the last hidden layer\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    # Tune the number and units in the dense layer including dropout\n",
    "    # Number of dense layers: 1 - 3\n",
    "    # Number of units: 16 - 512 with stepsize of 32\n",
    "    x = keras.layers.Dense(units=64,\n",
    "                            activation=\"relu\")(x)\n",
    "\n",
    "    # Add output layer\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    # TODO: maybe try with a softmax activation function\n",
    "\n",
    "    # define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[\"Accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build and compile the model for hyperparameter tuning\n",
    "\n",
    "def build_and_compile_model(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search. Model is compiled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : model\n",
    "        Compiled keras model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(inpt_comp1_diff.shape[1:]))\n",
    "    \n",
    "    # Tune the number of hidden CNN layers (pair of Conv3D and MaxPool) and filters + kernel_size in each hidden layer.\n",
    "    # Number of hidden layers: 1 - 5\n",
    "    # Number of filters: 16 - 512 with stepsize of 32\n",
    "    # Kernel size: 3 - 5 with stepsize of 2\n",
    "    for i in range(1, hp.Int(\"num_layers\", 2, 6)):\n",
    "        \n",
    "        x = keras.layers.Conv3D(\n",
    "            filters=hp.Int(\"filters_\" + str(i), min_value=16, max_value=512, step=32),\n",
    "            kernel_size=hp.Int(\"kernel_size_\" + str(i), min_value=3, max_value=5, step=2),\n",
    "            # kernel_regularizer=hp.Float(\"l2_regularization_\" + str(i), min_value=0.0001, max_value=0.01, step=0.0001),\n",
    "            activation=\"relu\", \n",
    "            padding=\"same\")(inputs)\n",
    "\n",
    "        x = keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "        # tune dropout layer with values from 0 - 0.3 with stepsize of 0.1\n",
    "        x = keras.layers.Dropout(hp.Float(\"dropout_\" + str(i), \n",
    "                                    min_value=0, max_value=0.3, step=0.1))(x)\n",
    "    \n",
    "    # Flatten the output of the last hidden layer\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    # Tune the number and units in the dense layer including dropout\n",
    "    # Number of dense layers: 1 - 3\n",
    "    # Number of units: 16 - 512 with stepsize of 32\n",
    "    for i in range(1, hp.Int(\"num_dense_layers\", 2, 4)):\n",
    "        x = keras.layers.Dense(units=hp.Int(\"units_\" + str(i), min_value=16, max_value=512, step=32),\n",
    "                               activation=\"relu\")(x)\n",
    "        \n",
    "        # tune dropout layer with values from 0 - 0.3 with stepsize of 0.1\n",
    "        x = keras.layers.Dropout(hp.Float(\"dense_dropout_\" + str(i), \n",
    "                                    min_value=0, max_value=0.3, step=0.1))(x)\n",
    "\n",
    "    # Add output layer\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    # TODO: maybe try with a softmax activation function\n",
    "\n",
    "    # define the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Tune learning rate for Adam optimizer with values from 0.01, 0.001, or 0.00001\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-5])\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[\"Accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = kt.BayesianOptimization(build_and_compile_model_test,\n",
    "                                objective=\"val_Accuracy\",\n",
    "                                max_trials=10,\n",
    "                                executions_per_trial=2,\n",
    "                                directory=\"kt_dir\",\n",
    "                                project_name=\"kt_BayesianOptimization\",\n",
    "                                overwrite=True)\n",
    "\n",
    "# Display search space summary\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the search for the best hyperparameters\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_Accuracy', patience=5)\n",
    "\n",
    "tuner.search(x_train, y_train, \n",
    "                epochs=20, \n",
    "                batch_size=4,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=[stop_early], \n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters from the results\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build model\n",
    "h_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the hypertuned model\n",
    "h_model.fit(x_train, y_train, epochs=20, validation_split=0.2, callbacks=[stop_early], verbose=2)\n",
    "\n",
    "# Evaluate model on test set\n",
    "h_model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with entire training data (no validation data)\n",
    "# callback to stop training when loss does not improve anymore and save the best model\n",
    "callback_list = [callbacks.EarlyStopping(monitor=\"loss\", patience=5),\n",
    "                 callbacks.ModelCheckpoint(filepath=\"./MVPA_CNN_model.keras\", \n",
    "                                            monitor=\"loss\",\n",
    "                                            save_best_only=True)]\n",
    "\n",
    "# build and compile the model\n",
    "model = build_and_compile_model()\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=4,\n",
    "                    callbacks=callback_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "695fa3b5085d3a33b386b9e0bb002d8067f80de939df75f6fbc1e8a95582c89a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
