{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H2O autoML applied to 3D data (MVPA and ICA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the data prep is from the file MVPA_data_prep_for_CNN as has been slightly changed for the h2o input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='dalcowks', release='5.13.0-40-generic', version='#45~20.04.1-Ubuntu SMP Mon Apr 4 09:38:31 UTC 2022', machine='x86_64')\n"
     ]
    }
   ],
   "source": [
    "# path to data\n",
    "#  - on Windows: C:/Users/tahendry/Desktop/Masterthesis_Reto/\n",
    "#  - on Linux:   ../data/\n",
    "\n",
    "try:\n",
    "    print(os.uname())\n",
    "    data_path = \"../data/\"\n",
    "except:\n",
    "    print(\"Windows\")\n",
    "    data_path = \"C:/Users/tahendry/Desktop/Masterthesis_Reto/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conn_SubjNr</th>\n",
       "      <th>VPNr</th>\n",
       "      <th>Cond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Conn_SubjNr  VPNr  Cond\n",
       "0            1     1     0\n",
       "1            2     2     0\n",
       "2            3     4     0\n",
       "3            4     6     1\n",
       "4            5     7     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the excel-file with the labels\n",
    "label_file = \"Conn_IDs_Matching.xlsx\"\n",
    "\n",
    "# read excel with only the first three columns\n",
    "label_df = (pd.read_excel(os.path.join(data_path, label_file),\n",
    "                            usecols=[0, 1, 2])\n",
    "            .replace({\"Cond\": {1: 0}})\n",
    "            .replace({\"Cond\": {2: 1}})\n",
    "            )\n",
    "\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BETA_Subject001_Condition002_Measure002_Component001.nii', 'BETA_Subject002_Condition002_Measure002_Component001.nii', 'BETA_Subject003_Condition002_Measure002_Component001.nii', 'BETA_Subject004_Condition002_Measure002_Component001.nii', 'BETA_Subject005_Condition002_Measure002_Component001.nii']\n"
     ]
    }
   ],
   "source": [
    "# read MVPA data\n",
    "path_content = os.listdir(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\"))\n",
    "\n",
    "# make two lists with pre (Condition002) and post (Condition003) data of first component\n",
    "comp1_pre = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition002\" in x])\n",
    "comp1_post = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition003\" in x])\n",
    "\n",
    "print(comp1_pre[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read nifti and save as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# create a dataset with the difference of pre and post data\n",
    "comp1_diff = []\n",
    "for pre, post in zip(comp1_pre, comp1_post):\n",
    "    pre_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", pre))\n",
    "    post_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", post))\n",
    "    pre_vol_data = pre_vol.get_fdata()\n",
    "    post_vol_data = post_vol.get_fdata()\n",
    "    diff_vol_data = post_vol_data - pre_vol_data\n",
    "    comp1_diff.append(diff_vol_data)\n",
    "\n",
    "# check the shape of the data\n",
    "print(comp1_diff[0].shape)\n",
    "\n",
    "# check the type of the data\n",
    "print(type(comp1_diff[0]))\n",
    "\n",
    "# takes about 4 mins to run on Dell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of one list element before stacking: comp1_diff[0].shape=(91, 109, 91)\n",
      "shape of one list element after stacking: inpt_comp1_diff.shape=(68, 91, 109, 91)\n",
      "inpt_comp1_diff.shape=(68, 902629)\n",
      "inpt_comp1_diff.mean()=1.1534273733013825e-16\n",
      "inpt_comp1_diff.std()=0.9999999999999816\n"
     ]
    }
   ],
   "source": [
    "# stack the data to later use it as input for the CNN\n",
    "# note: the first dimension is the number of samples\n",
    "print(f\"shape of one list element before stacking: {comp1_diff[0].shape=}\")\n",
    "inpt_comp1_diff = np.stack(comp1_diff, axis=0)\n",
    "print(f\"shape of one list element after stacking: {inpt_comp1_diff.shape=}\")\n",
    "\n",
    "# reshape the data into a flat array\n",
    "inpt_comp1_diff = inpt_comp1_diff.reshape(68, -1)\n",
    "\n",
    "# normalize the input data (zero mean, unit variance)\n",
    "# note: a CNN works best with normalized data\n",
    "inpt_comp1_diff = (inpt_comp1_diff - inpt_comp1_diff.mean()) / inpt_comp1_diff.std()\n",
    "\n",
    "print(f\"{inpt_comp1_diff.shape=}\",\n",
    "      f\"{inpt_comp1_diff.mean()=}\",\n",
    "      f\"{inpt_comp1_diff.std()=}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape=(54, 91, 109, 91, 1)\n",
      "x_test.shape=(14, 91, 109, 91, 1)\n",
      "y_train.shape=(54,)\n",
      "y_test.shape=(14,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test data\n",
    "# use 80% of the data for training and 20% for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(inpt_comp1_diff, \n",
    "                                                    label_df[\"Cond\"], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# check the shape of the data\n",
    "print(f\"{x_train.shape=}\",\n",
    "        f\"{x_test.shape=}\",\n",
    "        f\"{y_train.shape=}\",\n",
    "        f\"{y_test.shape=}\", sep=\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start H2O training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the H2O cluster (locally)\n",
    "h2o.init()\n",
    "\n",
    "# Import a sample binary outcome train/test set into H2O\n",
    "train = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_train_10k.csv\")\n",
    "test = h2o.import_file(\"https://s3.amazonaws.com/erin-data/higgs/higgs_test_5k.csv\")\n",
    "\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "y = \"response\"\n",
    "x.remove(y)\n",
    "\n",
    "# For binary classification, response should be a factor\n",
    "train[y] = train[y].asfactor()\n",
    "test[y] = test[y].asfactor()\n",
    "\n",
    "# Run AutoML for 20 base models\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate predictions on a test set, you can make predictions\n",
    "# directly on the `H2OAutoML` object ...\n",
    "preds = aml.predict(test)\n",
    "print(preds)\n",
    "\n",
    "# ... or on the leader model object directly\n",
    "preds_lead = aml.leader.predict(test)\n",
    "print(preds_lead)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_h2o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "568949f3300de056dad872d23e0d42a26a39e1939f2d1c0c069655a6a4cea437"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
