{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDate: 10.03.2023\\nAuthor: Reto Hendry\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Date: 10.03.2023\n",
    "Author: Reto Hendry\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posix.uname_result(sysname='Linux', nodename='dalcowks', release='5.13.0-40-generic', version='#45~20.04.1-Ubuntu SMP Mon Apr 4 09:38:31 UTC 2022', machine='x86_64')\n",
      "['BETA_Subject001_Condition002_Measure002_Component001.nii', 'BETA_Subject002_Condition002_Measure002_Component001.nii', 'BETA_Subject003_Condition002_Measure002_Component001.nii', 'BETA_Subject004_Condition002_Measure002_Component001.nii', 'BETA_Subject005_Condition002_Measure002_Component001.nii']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%% import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import time\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#%% filepath\n",
    "# path to data\n",
    "#  - on Windows: C:/Users/tahendry/Desktop/Masterthesis_Reto/\n",
    "#  - on Linux:   ../data/\n",
    "\n",
    "try:\n",
    "    print(os.uname())\n",
    "    data_path = \"../data/\"\n",
    "except:\n",
    "    print(\"Windows\")\n",
    "    data_path = \"C:/Users/tahendry/Desktop/Masterthesis_Reto/\"\n",
    "\n",
    "# read in the excel-file with the labels\n",
    "label_file = \"Conn_IDs_Matching.xlsx\"\n",
    "\n",
    "# read excel with only the first three columns\n",
    "label_df = (pd.read_excel(os.path.join(data_path, label_file),\n",
    "                            usecols=[0, 1, 2])\n",
    "            .replace({\"Cond\": {1: 0}})\n",
    "            .replace({\"Cond\": {2: 1}})\n",
    "            )\n",
    "\n",
    "label_df.head()\n",
    "\n",
    "# read MVPA data\n",
    "path_content = os.listdir(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\"))\n",
    "\n",
    "# make two lists with pre (Condition002) and post (Condition003) data of first component\n",
    "comp1_pre = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition002\" in x])\n",
    "comp1_post = sorted([x for x in path_content \n",
    "                    if \"Component001\" in x \n",
    "                    and \"Condition003\" in x])\n",
    "\n",
    "print(comp1_pre[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91)\n",
      "<class 'numpy.ndarray'>\n",
      "shape of one list element before stacking: comp1_diff[0].shape=(91, 109, 91)\n",
      "inpt_comp1_diff.shape=(68, 902629)\n",
      "inpt_comp1_diff.mean()=0.0005298948701831914\n",
      "inpt_comp1_diff.std()=0.22370761343748158\n",
      "x_train.shape=(54, 902629)\n",
      "x_test.shape=(14, 902629)\n",
      "y_train.shape=(54,)\n",
      "y_test.shape=(14,)\n"
     ]
    }
   ],
   "source": [
    "#%% prepare data\n",
    "# create a dataset with the difference of pre and post data\n",
    "comp1_diff = []\n",
    "for pre, post in zip(comp1_pre, comp1_post):\n",
    "    pre_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", pre))\n",
    "    post_vol = nib.load(os.path.join(data_path, \"Denoised_Data_6mm\", \"MVPA_data\", post))\n",
    "    pre_vol_data = pre_vol.get_fdata()\n",
    "    post_vol_data = post_vol.get_fdata()\n",
    "    diff_vol_data = post_vol_data - pre_vol_data\n",
    "    comp1_diff.append(diff_vol_data)\n",
    "\n",
    "# check the shape of the data\n",
    "print(comp1_diff[0].shape)\n",
    "\n",
    "# check the type of the data\n",
    "print(type(comp1_diff[0]))\n",
    "\n",
    "# stack the data to later use it as input for the CNN\n",
    "# note: the first dimension is the number of samples\n",
    "print(f\"shape of one list element before stacking: {comp1_diff[0].shape=}\")\n",
    "inpt_comp1_diff = np.stack(comp1_diff, axis=0)\n",
    "\n",
    "# expand the dimensions to fit the input shape of the CNN\n",
    "# note: the last dimension is the number of channels\n",
    "inpt_comp1_diff = np.expand_dims(inpt_comp1_diff, axis=-1)\n",
    "\n",
    "# normalize the input data (zero mean, unit variance)\n",
    "# note: a CNN works best with normalized data\n",
    "# inpt_comp1_diff = (inpt_comp1_diff - inpt_comp1_diff.mean()) / inpt_comp1_diff.std()\n",
    "\n",
    "# transform the data from a 3d array to a 2d array\n",
    "x_dim = inpt_comp1_diff.shape[1]  # 91\n",
    "y_dim = inpt_comp1_diff.shape[2]  # 109\n",
    "z_dim = inpt_comp1_diff.shape[3]  # 91\n",
    "num_samples = inpt_comp1_diff.shape[0]\n",
    "inpt_comp1_diff = inpt_comp1_diff.reshape(num_samples, x_dim*y_dim*z_dim)\n",
    "\n",
    "\n",
    "print(f\"{inpt_comp1_diff.shape=}\",\n",
    "      f\"{inpt_comp1_diff.mean()=}\",\n",
    "      f\"{inpt_comp1_diff.std()=}\", sep=\"\\n\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(inpt_comp1_diff, \n",
    "                                                    label_df[\"Cond\"], \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=label_df[\"Cond\"]\n",
    "                                                    )\n",
    "\n",
    "# check the shape of the data\n",
    "print(f\"{x_train.shape=}\",\n",
    "        f\"{x_test.shape=}\",\n",
    "        f\"{y_train.shape=}\",\n",
    "        f\"{y_test.shape=}\", sep=\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% define the autoML class\n",
    "# Define the cross-validation strategy\n",
    "cv_stratified = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def tpot_class(nbr_generations, nbr_population_size, max_time=None):\n",
    "    tpot = TPOTClassifier(generations=nbr_generations,  # number of iterations for optimization\n",
    "                        population_size=nbr_population_size,  # default 100\n",
    "                        max_time_mins=max_time,\n",
    "                        early_stop=5,\n",
    "                        scoring=\"accuracy\",\n",
    "                        cv=cv_stratified,  # cross validation fold (default)\n",
    "                        n_jobs=-1, # nbr. of cores used (-1 = all)\n",
    "                        max_eval_time_mins=10,  # default 5\n",
    "                        random_state=1,  # seed\n",
    "                        memory=False,  # avoid fitting same model\n",
    "                        periodic_checkpoint_folder=\"./tpot_folder\",\n",
    "                        verbosity=3,  # print minimal info\n",
    "                        log_file=\"tpot_log\",\n",
    "                        )\n",
    "    return tpot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5378eac8c5a4462f8a256b8e562e7d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/6 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tahendry/miniconda3/envs/env_tpot_pip/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:794: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation and pop_size: 2\n",
      "trained pipelines: 6\n",
      "best model: Pipeline(steps=[('stackingestimator',\n",
      "                 StackingEstimator(estimator=GradientBoostingClassifier(learning_rate=0.001,\n",
      "                                                                        max_depth=8,\n",
      "                                                                        max_features=0.7500000000000001,\n",
      "                                                                        min_samples_leaf=16,\n",
      "                                                                        min_samples_split=14,\n",
      "                                                                        random_state=1,\n",
      "                                                                        subsample=0.2))),\n",
      "                ('rbfsampler', RBFSampler(gamma=0.4, random_state=1)),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=10,\n",
      "                                        min_samples_leaf=12,\n",
      "                                        min_samples_split=7, random_state=1))])\n",
      "best model score: 0.2857142857142857\n",
      "time needed: 1.21 mins\n",
      "\n",
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab09b175cfac473a9d440b58d72c7f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/20 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tahendry/miniconda3/envs/env_tpot_pip/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:794: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation and pop_size: 4\n",
      "trained pipelines: 18\n",
      "best model: Pipeline(steps=[('rbfsampler', RBFSampler(gamma=0.4, random_state=1)),\n",
      "                ('nystroem',\n",
      "                 Nystroem(gamma=0.15000000000000002, kernel='poly',\n",
      "                          n_components=9, random_state=1)),\n",
      "                ('decisiontreeclassifier',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=10,\n",
      "                                        min_samples_leaf=12,\n",
      "                                        min_samples_split=7, random_state=1))])\n",
      "best model score: 0.5714285714285714\n",
      "time needed: 21.36 mins\n",
      "\n",
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08484f3a2354d629a44f5cd76430a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/42 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tahendry/miniconda3/envs/env_tpot_pip/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:794: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation and pop_size: 6\n",
      "trained pipelines: 39\n",
      "best model: Pipeline(steps=[('mlpclassifier',\n",
      "                 MLPClassifier(alpha=0.001, learning_rate_init=0.01,\n",
      "                               random_state=1))])\n",
      "best model score: 0.5714285714285714\n",
      "time needed: 44.28 mins\n",
      "\n",
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e79f957ed2e469390c8d2d682a95e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/72 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tahendry/miniconda3/envs/env_tpot_pip/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:794: FutureWarning: sklearn.metrics.SCORERS is deprecated and will be removed in v1.3. Please use sklearn.metrics.get_scorer_names to get a list of available scorers and sklearn.metrics.get_metric to get scorer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation and pop_size: 8\n",
      "trained pipelines: 52\n",
      "best model: Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.15000000000000002, kernel='poly',\n",
      "                          n_components=9, random_state=1)),\n",
      "                ('gradientboostingclassifier',\n",
      "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=9,\n",
      "                                            max_features=0.7000000000000001,\n",
      "                                            min_samples_leaf=7,\n",
      "                                            min_samples_split=6, random_state=1,\n",
      "                                            subsample=0.6000000000000001))])\n",
      "best model score: 0.7142857142857143\n",
      "time needed: 52.03 mins\n",
      "\n",
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec3dc4947244aaeb155f046cc881156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/110 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model incrementally and evaluate the best pipelines after each iteration\n",
    "# start timer to measure the time\n",
    "parameter_list = [8, 10]\n",
    "\n",
    "for i in parameter_list:\n",
    "    tpot = tpot_class(nbr_generations=i, nbr_population_size=i)\n",
    "    start = time.time()\n",
    "    tpot.fit(x_train, y_train)\n",
    "    print(f\"generation and pop_size: {i}\",\n",
    "          f\"trained pipelines: {len(tpot.evaluated_individuals_)}\",\n",
    "          f\"best model: {tpot.fitted_pipeline_}\",\n",
    "          f\"best model score: {tpot.score(x_test, y_test)}\",\n",
    "          f\"time needed: {(time.time() - start)/60:.2f} mins\",\n",
    "          sep=\"\\n\", end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% fit the model\n",
    "tpot.fit(x_train, y_train)\n",
    "print(\"done with fitting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% evaluate the model\n",
    "print(\"pipeline: /n\", tpot.fitted_pipeline_)\n",
    "print(tpot.score(x_test, y_test))\n",
    "tpot.export('tpot_pipeline.py')\n",
    "print(\"best pipeline exported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tpot_pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Mar  1 2023, 18:23:06) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4d54ec3bd672709454c9a9b79935a93959c78963a0f798583835c6bddec5b34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
